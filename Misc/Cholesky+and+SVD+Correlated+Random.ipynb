{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cholesky and Singular Value Decomposition to generated correlated random numbers\n",
    "## The problem:\n",
    "The ability to simulate correlated risk factors is key to many risk models. Historical Simulation achieves this implicitly, by using actual timeseries data for risk factors and applying changes for all risk factors for a given day, for a large number of days (250 or 500 typically). The empirically observed correlations, as well as the means and standard deviations, are implicitly embedded across the historical timeseries data sets.\n",
    "\n",
    "If we are doing *Monte Carlo* simulation however we need to do something different, since random drawings from a Normal(Gaussian)distribution will be uncorrelated - whereas real data will exhibit correlations. Therefore a technique must be developed to transform uncorrelated random variables to variables which exhibit the empirically observed correlations.\n",
    "\n",
    "In this Jupyter notebook we explore some techniques for producing correlated random variables and variations on these techniques.\n",
    "- Cholesky Factorisation : $LL^T=\\Sigma$, using both covariance and correlation matrix variations to generate trials \n",
    "- Singular Value Decomposition : $UDV^T=\\Sigma$ [TODO - help appreciated!]\n",
    "## Theory - Cholesky Factorisation approach:\n",
    "Consider a random vector, X, consisting of uncorrelated random variables with each random variable, $X_i$, having zero mean and unit variance 1 ($X\\sim N(0,1)$). What we hant is some sort of technique for converting these standard normal variables to correlated variables which exhibit the observed empirical means and variances of theproblem we are modelling.\n",
    "\n",
    "\n",
    "- Useful identities and results:\n",
    "    - $\\mathbb E[XX^T] = I$, where $X\\sim N(0,1)$ Since $Var[XX^T]=\\mathbb E [XX^T] + \\mathbb E[X] \\mathbb E[X^T]$\n",
    "- To show that we can create new, correlated, random variables $Y$, where $Y=LX$ and\n",
    "    - $L$ is the Cholesky factorisation matrix (see above \"Cholesky\"), \n",
    "    - X is a vector of independent uncorrelated variables from a Normal distribution with mean of zero and variance of one : $\\boxed {X\\sim N(0,1)}$\n",
    "    - $Cov[Y,Y] = \\mathbb E[YY^T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$Demonstration~of~~ \\mathbb E[XX^T] = I, ~~where~X\\sim N(0,1)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4\n",
      "0  1.000231 -0.000385  0.000445 -0.000184  0.000035\n",
      "1 -0.000385  0.999603 -0.000424  0.000493  0.000033\n",
      "2  0.000445 -0.000424  1.000095  0.000400  0.000417\n",
      "3 -0.000184  0.000493  0.000400  1.000890 -0.000115\n",
      "4  0.000035  0.000033  0.000417 -0.000115  0.999320\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex, IFrame\n",
    "import pandas as pd\n",
    "#import pandas.io.data as pd_io\n",
    "from pandas_datareader import data, wb\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "G=pd.DataFrame(np.random.normal(size=(10000000,5)))\n",
    "m=pd.DataFrame(np.matmul(G.transpose(), G))\n",
    "display(Math(r'Demonstration~of~~ \\mathbb E[XX^T] = I, ~~where~X\\sim N(0,1)'))\n",
    "print(m/10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteDataError",
     "evalue": "No data fetched using 'GoogleDailyReader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b1584189e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msci\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WDC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IBM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MSFT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ORCL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[['Adj Close']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jxb/anaconda/lib/python2.7/site-packages/pandas_datareader/data.pyc\u001b[0m in \u001b[0;36mDataReader\u001b[0;34m(name, data_source, start, end, retry_count, pause, session, access_key)\u001b[0m\n\u001b[1;32m    313\u001b[0m                                  \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                                  session=session).read()\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jxb/anaconda/lib/python2.7/site-packages/pandas_datareader/base.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dl_mult_symbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dl_mult_symbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jxb/anaconda/lib/python2.7/site-packages/pandas_datareader/base.pyc\u001b[0m in \u001b[0;36m_dl_mult_symbols\u001b[0;34m(self, symbols)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"No data fetched using {0!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRemoteDataError\u001b[0m: No data fetched using 'GoogleDailyReader'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data, wb\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "stocks=['WDC', 'AAPL', 'IBM', 'MSFT', 'ORCL']\n",
    "p=data.DataReader(stocks,data_source='google')#[['Adj Close']]\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x114ec9ed0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "pivot_ui(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=p.ix[0]\n",
    "#df.pop('ATML') get rid of duff entry with NaNs!! - handy as you can just remove (and optionally save) a chunk!!\n",
    "df=np.log(df/df.shift(1) )\n",
    "df=df.dropna()\n",
    "print(\"Days:{}\".format(len(df)))\n",
    "corr=df.corr()\n",
    "print(corr)\n",
    "chol=np.linalg.cholesky(corr)\n",
    "#chol=sci.linalg.cholesky(corr, lower=True)\n",
    "print chol\n",
    "sigma=df.std()\n",
    "mu=df.mean()\n",
    "print(\"sigma=\\n{}\\n mu=\\n{}\".format(sigma,mu))\n",
    "#No generate random normal samples with observed means (\"mu\"s) and st_devs (\"sigma\"s)\n",
    "#G_rands=np.random.normal(loc=mu,scale=sigma,size=(1000,len(sigma)))\n",
    "G_rands=pd.DataFrame(np.random.normal(size=(1000000,len(sigma))))\n",
    "#G_Corr_rand=G_rands.dot(chol)\n",
    "G_Corr_rand=(chol.dot(G_rands.transpose())).transpose()\n",
    "# Now apply the std dev and mean by multiplation and addition, respectively - return as pandas df\n",
    "G_=pd.DataFrame(G_Corr_rand * np.broadcast_to(sigma,(1000000,len(sigma))) + np.broadcast_to(mu,(1000000,len(mu))))\n",
    "print(G_.head())\n",
    "print(corr)\n",
    "print(G_.corr())\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data, wb\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "\n",
    "stocks=['WDC', 'AAPL', 'IBM', 'MSFT', 'ORCL']\n",
    "p=data.DataReader(stocks,data_source='yahoo')[['Adj Close']]\n",
    "df=p.ix[0] #convert pandas \"panel\" to pandas \"data frame\"\n",
    "df=np.log(df/df.shift(1) )\n",
    "df=df.dropna()\n",
    "\n",
    "cov=df.cov()\n",
    "chol=np.linalg.cholesky(cov) # default is left/lower; use chol=sci.linalg.cholesky(cov, lower=False) otherwise\n",
    "print ('Cholesky L=\\n{}, \\nL^T=\\n{},\\nLL^T=\\n{}'.format(chol, chol.transpose(), chol.dot(chol.T)))\n",
    "\n",
    "G_rands=pd.DataFrame(np.random.normal(size=(1000000,len(sigma))))\n",
    "G_=pd.DataFrame((chol.dot(G_rands.transpose())).transpose())\n",
    "\n",
    "print(G_.head())\n",
    "print(cov)\n",
    "print(G_.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check for tiny size - LL^T should be equal to cov, so diff should be negligible\n",
    "chol.dot(chol.T) - cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (chol.dot(chol.T) - cov).max()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
