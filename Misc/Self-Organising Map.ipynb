{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Organising Map Example using Risk Intelligence\n",
    "This example notebook demonstrates an implementation of a [Self-Organising Map](https://en.wikipedia.org/wiki/Self-organizing_map) (SOM), which is a classic problem in unsupervised learning, useful for dimensional reduction and cluster identification and analysis. SOMs are considered a special case of [Recurrent Neural Networks](https://en.wikipedia.org/wiki/Recurrent_neural_network) (RNNs). \n",
    "\n",
    "SOMs, also known as _self-organising feature maps_ or _Kohonen_ maps, are sometimes constructed as grids, where each point represents an output node (or _neuron_). The output node set models the actual map of a SOM and represents its internal state. The elements of the output set, referred to as output nodes accordingly, possess two attributes each, a _**fixed position**_ and a _**mutable weight**_. The position refers to a node's topological location on the map, the weight holds the actual information payload associated with the node. During the learning process output node weights are modified, but topological positions are not changed.\n",
    "\n",
    "A set of _**input vectors**_ (frequently referred to as *training data*) is presented, where the dimensionality of the input vectors corresponds exactly to the dimensionality of the output nodes' weights. \n",
    "\n",
    "The learning process works as follows:\n",
    "1. For each input vector the set of output nodes is analysed and the closest matching node based on output node weights compared with the input vector components is found. The closest matching node is called the *Best Matching Unit* or BMU. \n",
    "1. The weights of the BMU are then adjusted to more closely match the input vector\n",
    "1. Output nodes adjacent or close to the BMU in topological space are also adjusted so their respective weights are closer to the BMU\n",
    "1. Once BMUs have been found (and any nearby nodes, as required) and the weights updated for all input vectors, the next iteration begins. The way weights are adjusted typically changes with each iteration (i.e. evolution over time).\n",
    "\n",
    "The update formula for a neuron v with weight vector $Wv(s)$ is ${W_{v}(s+1)=W_{v}(s)+\\theta (u,v,s)\\cdot \\alpha(s)\\cdot (D(t)-W_{v}(s))}$ \n",
    "where s is the step index, t an index into the training sample, u is the index of the BMU for D(t), α(s) is a monotonically decreasing learning coefficient and D(t) is the input vector; Θ(u, v, s) is the neighborhood function which gives the distance between the neuron u and the neuron v in step s.\n",
    "\n",
    "Depending on the implementations, t can scan the training data set systematically (t is 0, 1, 2...T-1, then repeat, T being the training sample's size), be randomly drawn from the data set (bootstrap sampling), or implement some other sampling method (such as jackknifing).\n",
    "\n",
    "## Objective - Colour map example\n",
    "In this example we take a set of randomly generated 3D colour vectors (i.e vectors with Red, Green Blue components) and map them onto a 2D surface in such a way that similar colours will end up in the same area of the 2D surface.\n",
    "\n",
    "The collection of random colur vectors are  *inputs* (also referred to as the _training data set_) and the 2D grid of RGB/weight vectors (i.e. the _neurons_) are outputs (the SOM in other words). Each point on the SOM has a *weight* vector associated with it that is the same number of dimensions as our input data, in this case 3 to match the 3 dimensions of our colours.\n",
    "\n",
    "## Projection of SOM onto tensorised Directed Acyclic Graph (DAG) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as patches\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 colours as initial test set\n",
    "#raw_data = np.array([[1, 0, 0], [0, 1, 0],\n",
    "#                     [0, 0.5, 0.25], [0, 0, 1],\n",
    "#                     [0, 0, 0.5], [1, 1, 0.2],\n",
    "#                     [1, 0.4, 0.25], [1, 0, 1]]).T * 255\n",
    "# or use random colours\n",
    "raw_data = np.random.randint(0, 255, (3, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd=raw_data\n",
    "rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dimensions = np.array([5, 5])\n",
    "n_iterations = 10000\n",
    "init_learning_rate = 0.01\n",
    "\n",
    "normalise_data = True\n",
    "\n",
    "# if True, assume all data on common scale\n",
    "# if False, normalise to [0 1] range along each column\n",
    "normalise_by_column = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "nd=network_dimensions\n",
    "nd.view()\n",
    "print((network_dimensions[0], network_dimensions[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish variables based on data\n",
    "m = raw_data.shape[0]\n",
    "n = raw_data.shape[1]\n",
    "\n",
    "# initial neighbourhood radius\n",
    "init_radius = max(network_dimensions[0], network_dimensions[1]) / 2\n",
    "# radius decay parameter\n",
    "time_constant = n_iterations / np.log(init_radius)\n",
    "\n",
    "data = raw_data\n",
    "# check if data needs to be normalised\n",
    "if normalise_data:\n",
    "    if normalise_by_column:\n",
    "        # normalise along each column\n",
    "        col_maxes = raw_data.max(axis=0)\n",
    "        data = raw_data / col_maxes[np.newaxis, :]\n",
    "    else:\n",
    "        # normalise entire dataset\n",
    "        data = raw_data / data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup random weights between 0 and 1\n",
    "# weight matrix needs to be one m-dimensional vector for each neuron in the SOM\n",
    "net = np.random.random((network_dimensions[0], network_dimensions[1], m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOM Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bmu(t, net, m):\n",
    "    \"\"\"\n",
    "        Find the best matching unit for a given vector, t, in the SOM\n",
    "        Returns: a (bmu, bmu_idx) tuple where bmu is the high-dimensional BMU\n",
    "                 and bmu_idx is the index of this vector in the SOM\n",
    "    \"\"\"\n",
    "    bmu_idx = np.array([0, 0])\n",
    "    # set the initial minimum distance to a huge number\n",
    "    min_dist = np.iinfo(np.int).max    \n",
    "    # calculate the high-dimensional distance between each neuron and the input\n",
    "    for x in range(net.shape[0]):\n",
    "        for y in range(net.shape[1]):\n",
    "            w = net[x, y, :].reshape(m, 1)\n",
    "            # don't bother with actual Euclidean distance, to avoid expensive sqrt operation\n",
    "            sq_dist = np.sum((w - t) ** 2)\n",
    "            if sq_dist < min_dist:\n",
    "                min_dist = sq_dist\n",
    "                bmu_idx = np.array([x, y])\n",
    "    # get vector corresponding to bmu_idx\n",
    "    bmu = net[bmu_idx[0], bmu_idx[1], :].reshape(m, 1)\n",
    "    # return the (bmu, bmu_idx) tuple\n",
    "    return (bmu, bmu_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_radius(initial_radius, i, time_constant):\n",
    "    return initial_radius * np.exp(-i / time_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_learning_rate(initial_learning_rate, i, n_iterations):\n",
    "    return initial_learning_rate * np.exp(-i / n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_influence(distance, radius):\n",
    "    return np.exp(-distance / (2* (radius**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOM Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    #print('Iteration %d' % i)\n",
    "    \n",
    "    # select a training example at random\n",
    "    t = data[:, np.random.randint(0, n)].reshape(np.array([m, 1]))\n",
    "    \n",
    "    # find its Best Matching Unit\n",
    "    bmu, bmu_idx = find_bmu(t, net, m)\n",
    "    \n",
    "    # decay the SOM parameters\n",
    "    r = decay_radius(init_radius, i, time_constant)\n",
    "    l = decay_learning_rate(init_learning_rate, i, n_iterations)\n",
    "    \n",
    "    # now we know the BMU, update its weight vector to move closer to input\n",
    "    # and move its neighbours in 2-D space closer\n",
    "    # by a factor proportional to their 2-D distance from the BMU\n",
    "    for x in range(net.shape[0]):\n",
    "        for y in range(net.shape[1]):\n",
    "            w = net[x, y, :].reshape(m, 1)\n",
    "            # get the 2-D distance (again, not the actual Euclidean distance)\n",
    "            w_dist = np.sum((np.array([x, y]) - bmu_idx) ** 2)\n",
    "            # if the distance is within the current neighbourhood radius\n",
    "            if w_dist <= r**2:\n",
    "                # calculate the degree of influence (based on the 2-D distance)\n",
    "                influence = calculate_influence(w_dist, r)\n",
    "                # now update the neuron's weight using the formula:\n",
    "                # new w = old w + (learning rate * influence * delta)\n",
    "                # where delta = input vector (t) - old w\n",
    "                new_w = w + (l * influence * (t - w))\n",
    "                # commit the new weight\n",
    "                net[x, y, :] = new_w.reshape(1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Colour Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEICAYAAACXj6vjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD8iuR2zlMjyEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112fbea10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "# setup axes\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "ax.set_xlim((0, net.shape[0]+1))\n",
    "ax.set_ylim((0, net.shape[1]+1))\n",
    "ax.set_title('Self-Organising Map after %d iterations' % n_iterations)\n",
    "\n",
    "# plot the rectangles\n",
    "for x in range(1, net.shape[0] + 1):\n",
    "    for y in range(1, net.shape[1] + 1):\n",
    "        ax.add_patch(patches.Rectangle((x-0.5, y-0.5), 1, 1,\n",
    "                     facecolor=net[x-1,y-1,:],\n",
    "                     edgecolor='none'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
